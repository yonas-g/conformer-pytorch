{
    "sample_rate": 16000,
    "feat_in": 80,
    "n_layers": 16,
    "d_model": 176,

    "subsampling": "striding",
    "subsampling_factor": 4,
    "subsampling_conv_channels": -1,
    "causal_downsampling": false,

    "ff_expansion_factor": 4,

    "self_attention_model": "rel_pos",
    "n_heads": 4,
    "att_context_size": [-1, -1],  
    "att_context_style": "regular",  
    "xscaling": true,  
    "untie_biases": true,  
    "pos_emb_max_len": 5000,

    "conv_kernel_size": 31,
    "conv_norm_type": "batch_norm",  
    "conv_context_size": null,  

    "dropout": 0.1, 
    "dropout_pre_encoder": 0.1, 
    "dropout_emb": 0.0,  
    "dropout_att": 0.1
}